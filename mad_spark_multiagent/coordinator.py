"""Coordinator for the Mad Spark Multi-Agent Workflow.

This module orchestrates the interaction between various specialized agents
(Idea Generator, Critic, Advocate, Skeptic) to generate, evaluate, and
refine ideas based on a given theme and constraints.

The main function, `run_multistep_workflow`, manages the flow:
1. Generates initial ideas.
2. Evaluates these ideas using a critic agent, expecting JSON-formatted scores
   and comments.
3. Selects top candidates based on scores.
4. For each top candidate, an advocate agent builds a case for it, and then
   a skeptic agent critically analyzes it.
5. Returns a compiled list of results including the idea, its evaluations,
   advocacy, and skepticism.

Environment variables GOOGLE_API_KEY and GOOGLE_GENAI_MODEL must be set,
typically in a .env file, for the agents to function.
"""
import os
import json
from typing import List, Dict, Any, Optional

# SECURITY NOTE: Storing API keys directly in environment variables is suitable for
# local development but not recommended for production.
# Consider using a dedicated secret management service for production deployments.

try:
    from dotenv import load_dotenv
    if os.path.exists(".env"):
        print("Coordinator: .env file found, loading environment variables.")
        load_dotenv()
    else:
        print("Coordinator: .env file not found, relying on environment variables.")
except ImportError:
    print("Coordinator: python-dotenv not found, .env file will not be loaded.\n"
          "Ensure GOOGLE_API_KEY and GOOGLE_GENAI_MODEL are set in your environment.")

# Check for GOOGLE_API_KEY and GOOGLE_GENAI_MODEL after attempting to load .env.
# These are required for ADK agent initialization.
api_key: Optional[str] = os.getenv("GOOGLE_API_KEY")
model_name: Optional[str] = os.getenv("GOOGLE_GENAI_MODEL")

if not api_key:
    print("\nFATAL: GOOGLE_API_KEY is not set in the environment or .env file.")
    print("Please set the GOOGLE_API_KEY environment variable.")
    print("Example for .env file: GOOGLE_API_KEY='your_actual_api_key_here'")
    print("If not using .env, ensure it's exported in your shell.")
    print("Ensure `python-dotenv` is installed (`pip install python-dotenv`) if using .env.")
    exit(1)
else:
    os.environ["GOOGLE_API_KEY"] = api_key

if not model_name:
    print("\nWARNING: GOOGLE_GENAI_MODEL is not set in the environment or .env file.")
    print("The agents in this application expect this to be set (e.g., 'gemini-pro').")
    print("Example for .env file: GOOGLE_GENAI_MODEL='gemini-pro'")
    print("Proceeding, but agent initialization or calls may fail if a model is not found.")

# Agents are imported after environment variable checks and setup.
from mad_spark_multiagent.agent_defs import (
    idea_generator_agent,
    critic_agent,
    advocate_agent,
    skeptic_agent,
)
# For type hinting Agent instances if needed, though they are used directly here.
from google.adk.agents import Agent


# Define a type alias for the candidate data structure for clarity
CandidateData = Dict[str, Any] # Keys: "idea", "initial_score", "initial_critique", "advocacy", "skepticism"
EvaluatedIdea = Dict[str, Any] # Keys: "text", "score", "critique"


def run_multistep_workflow(
    theme: str, constraints: str, num_top_candidates: int = 2
) -> List[CandidateData]:
    """
    Runs the multi-step idea generation and refinement workflow.

    Args:
        theme: The central theme for idea generation.
        constraints: A string outlining constraints or specific criteria for
                     ideas and their evaluation.
        num_top_candidates: The number of top-scoring ideas to process through
                            advocacy and skepticism stages.

    Returns:
        A list of dictionaries, where each dictionary contains detailed
        information about a processed candidate idea, including its score,
        critique, advocacy, and skepticism. Returns an empty list if critical
        errors occur early in the process (e.g., idea generation fails).
    """
    final_candidates_data: List[CandidateData] = []
    raw_generated_ideas: str = ""
    parsed_ideas: List[str] = []

    # 1. Generate Ideas
    try:
        print(f"Coordinator: Generating ideas for theme '{theme}'...")
        # Assuming call_tool returns str; ADK might have more specific types.
        agent_response_ideas: Any = idea_generator_agent.call_tool(
            "generate_ideas", topic=theme, context=constraints
        )
        raw_generated_ideas = str(agent_response_ideas) # Ensure it's a string

        parsed_ideas = [idea.strip() for idea in raw_generated_ideas.split("\n") if idea.strip()]
        if not parsed_ideas:
            print("Coordinator: No ideas were generated by IdeaGeneratorAgent.")
            return []
        print(f"Coordinator: Generated {len(parsed_ideas)} raw ideas.")
    except Exception as e:
        print(f"Coordinator Error: IdeaGeneratorAgent failed to generate ideas. Error: {str(e)}")
        return []

    # 2. Evaluate Ideas
    raw_evaluations: str = ""
    evaluated_ideas_data: List[EvaluatedIdea] = []

    try:
        print(f"Coordinator: Evaluating {len(parsed_ideas)} ideas...")
        agent_response_evals: Any = critic_agent.call_tool(
            "evaluate_ideas",
            ideas="\n".join(parsed_ideas),
            criteria=constraints,
            context=theme,
        )
        raw_evaluations = str(agent_response_evals) # Ensure it's a string
        print(f"Coordinator: Raw evaluations received:\n{raw_evaluations}")

        json_evaluation_lines: List[str] = [
            line.strip() for line in raw_evaluations.split("\n") if line.strip()
        ]

        if len(json_evaluation_lines) != len(parsed_ideas):
            print(
                f"Coordinator Warning: Mismatch between number of ideas ({len(parsed_ideas)}) "
                f"and number of evaluation lines ({len(json_evaluation_lines)})."
                " Will attempt to process based on the shorter list, or ideas without evaluations will get defaults."
            )

        for i, idea_text in enumerate(parsed_ideas):
            score: int = 0
            critique: str = "Evaluation not available or parsing failed."

            if i < len(json_evaluation_lines):
                json_line: str = json_evaluation_lines[i]
                try:
                    eval_data: Dict[str, Any] = json.loads(json_line)
                    score = int(eval_data.get("score", 0))
                    critique = str(eval_data.get("comment", "No comment provided."))
                except json.JSONDecodeError:
                    print(f"Coordinator Warning: Could not parse JSON from CriticAgent for idea: '{idea_text[:50]}...'. JSON: '{json_line}'")
                    critique = "Failed to parse JSON evaluation from CriticAgent."
                except ValueError:
                    print(f"Coordinator Warning: Could not parse score as int for idea: '{idea_text[:50]}...'. JSON: '{json_line}'")
                    critique = "Failed to parse score as integer from CriticAgent's evaluation."
                except Exception as e:
                    print(f"Coordinator Warning: Unexpected error parsing evaluation for idea: '{idea_text[:50]}...'. Error: {e}. JSON: '{json_line}'")
                    critique = f"Unexpected error parsing evaluation: {e}"
            else:
                print(f"Coordinator Warning: No evaluation received from CriticAgent for idea: '{idea_text[:50]}...' (expected {len(parsed_ideas)}, got {len(json_evaluation_lines)}).")

            evaluated_ideas_data.append({"text": idea_text, "score": score, "critique": critique})

        evaluated_ideas_data.sort(key=lambda x: x.get("score", 0), reverse=True)
        top_candidates: List[EvaluatedIdea] = evaluated_ideas_data[:num_top_candidates]

        if not top_candidates and parsed_ideas:
             print("Coordinator: No ideas were selected as top candidates "
                   "(e.g., all failed parsing, had 0 score, or num_top_candidates is 0).")

        print(f"Coordinator: Selected {len(top_candidates)} top candidates for further processing.")

    except Exception as e:
        print(f"Coordinator Error: CriticAgent failed during evaluation phase. Error: {str(e)}")
        if parsed_ideas:
            print(f"Coordinator: Falling back to using the first {min(num_top_candidates, len(parsed_ideas))} raw ideas due to CriticAgent failure.")
            top_candidates = [{"text": idea, "critique": "N/A (CriticAgent failed)", "score": 0} for idea in parsed_ideas[:min(num_top_candidates, len(parsed_ideas))]]
        else:
            return []
        if not top_candidates and parsed_ideas:
            print("Coordinator: Fallback selection after CriticAgent failure resulted in no candidates.")
            return []


    # 3. Advocate and Criticize for top N candidates
    for candidate in top_candidates:
        idea_text: str = str(candidate.get("text", "Unknown Idea"))
        evaluation_detail: str = str(candidate.get("critique", "N/A"))
        advocacy_output: str = "N/A"
        skepticism_output: str = "N/A"

        print(f"\nCoordinator: Processing candidate: {idea_text} (Score: {candidate.get('score',0)})")

        try:
            print(f"Coordinator: Advocating for idea: '{idea_text}'...")
            agent_advocate_response: Any = advocate_agent.call_tool(
                "advocate_idea",
                idea=idea_text,
                evaluation=evaluation_detail,
                context=theme,
            )
            advocacy_output = str(agent_advocate_response)
            if not advocacy_output.strip():
                 advocacy_output = "AdvocateAgent returned no content."
        except Exception as e:
            print(f"Coordinator Warning: AdvocateAgent failed for idea '{idea_text}'. Error: {str(e)}")
            advocacy_output = "Advocacy not available due to agent error."

        try:
            print(f"Coordinator: Skepticizing idea: '{idea_text}'...")
            agent_skeptic_response: Any = skeptic_agent.call_tool(
                "criticize_idea",
                idea=idea_text,
                advocacy=advocacy_output,
                context=theme,
            )
            skepticism_output = str(agent_skeptic_response)
            if not skepticism_output.strip():
                skepticism_output = "SkepticAgent returned no content."
        except Exception as e:
            print(f"Coordinator Warning: SkepticAgent failed for idea '{idea_text}'. Error: {str(e)}")
            skepticism_output = "Skepticism not available due to agent error."

        final_candidates_data.append({
            "idea": idea_text,
            "initial_score": candidate.get("score", 0),
            "initial_critique": evaluation_detail,
            "advocacy": advocacy_output,
            "skepticism": skepticism_output,
        })
        print(f"Coordinator: Finished processing for: {idea_text}")

    return final_candidates_data


if __name__ == "__main__":
    print("Starting Mad Spark Multi-Agent Workflow...")

    sample_theme: str = "Sustainable Urban Living"
    sample_constraints: str = (
        "Ideas should be implementable within a typical city budget, focus on "
        "community involvement, and be technologically feasible within the next 5 "
        "years. Ideas should also consider scalability and inclusivity."
    )
    num_ideas_to_process: int = 1

    print(f"\nTheme: {sample_theme}")
    print(f"Constraints: {sample_constraints}")
    print(f"Number of top ideas to fully process: {num_ideas_to_process}\n")

    results: List[CandidateData] = run_multistep_workflow(
        theme=sample_theme,
        constraints=sample_constraints,
        num_top_candidates=num_ideas_to_process
    )

    print("\n--- Final Results ---")
    if results:
        print(json.dumps(results, indent=2))
    else:
        print("No results were generated from the workflow.")

    print("\nMad Spark Multi-Agent Workflow Finished.")
