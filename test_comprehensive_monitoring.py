"""Test comprehensive token monitoring with real API calls."""
from madspark.core.coordinator_batch import run_multistep_workflow_batch
from madspark.utils.batch_monitor import get_batch_monitor, reset_batch_monitor
import time

print('ğŸš€ Comprehensive Token Monitoring Test')
print('=' * 50)

# Reset monitor for clean test
reset_batch_monitor()

print('\nğŸ“Š Test: 2 Candidates with Full Token Monitoring')
print('-' * 50)

start_time = time.time()
try:
    results = run_multistep_workflow_batch(
        theme='Efficient Public Transportation',
        constraints='Environmentally friendly and cost-effective',
        num_top_candidates=2,
        verbose=False
    )
    
    duration = time.time() - start_time
    print(f'\nâœ… Completed in {duration:.2f} seconds')
    print(f'ğŸ“‹ Results: {len(results)} candidates processed')
    
    # Show detailed monitoring results
    print('\nğŸ“ˆ Detailed Monitoring Results')
    print('-' * 30)
    monitor = get_batch_monitor()
    summary = monitor.get_session_summary()
    
    print(f'Total API calls: {summary["total_calls"]}')
    print(f'Successful calls: {summary["successful_calls"]}/{summary["total_calls"]}')
    print(f'Items processed: {summary["total_items_processed"]}')
    print(f'Processing time: {summary["total_processing_time_seconds"]:.2f}s')
    print(f'Items per second: {summary.get("average_items_per_second", 0):.2f}')
    
    if summary.get('total_tokens_used', 0) > 0:
        tokens = summary["total_tokens_used"]
        items = summary["total_items_processed"]
        print(f'ğŸ”¤ Total tokens: {tokens:,} ({tokens/items:.0f} per item)')
        
        if summary.get('total_estimated_cost_usd'):
            cost = summary["total_estimated_cost_usd"]
            print(f'ğŸ’µ Estimated cost: ${cost:.4f} (${cost/items:.4f} per item)')
    
    # Detailed breakdown by batch type
    if summary.get('batch_type_breakdown'):
        print('\nğŸ“Š Batch Type Analysis:')
        total_batch_calls = 0
        total_individual_calls_estimate = 0
        
        for batch_type, stats in summary['batch_type_breakdown'].items():
            calls = stats["calls"]
            items = stats["items"]
            tokens = stats.get("tokens", 0)
            cost = stats.get("cost", 0)
            
            # Calculate efficiency
            items_per_call = items / calls if calls > 0 else 0
            tokens_per_item = tokens / items if items > 0 and tokens > 0 else 0
            
            total_batch_calls += calls
            total_individual_calls_estimate += items
            
            print(f'  {batch_type}:')
            print(f'    â€¢ {calls} batch calls vs {items} individual calls would be')
            print(f'    â€¢ {items_per_call:.1f} items per batch call')
            if tokens > 0:
                print(f'    â€¢ {tokens:,} tokens ({tokens_per_item:.0f} per item)')
            if cost > 0:
                print(f'    â€¢ ${cost:.4f} cost')
        
        # Overall API call reduction
        call_reduction = ((total_individual_calls_estimate - total_batch_calls) / total_individual_calls_estimate * 100) if total_individual_calls_estimate > 0 else 0
        print(f'\nğŸ“ API Call Efficiency:')
        print(f'  â€¢ Batch calls: {total_batch_calls}')
        print(f'  â€¢ Individual calls would be: {total_individual_calls_estimate}')
        print(f'  â€¢ Reduction: {call_reduction:.1f}%')
    
    # Cost effectiveness analysis
    print('\nğŸ’° Cost Effectiveness Analysis:')
    analysis = monitor.analyze_cost_effectiveness()
    
    if analysis.get('batch_effectiveness'):
        for batch_type, stats in analysis['batch_effectiveness'].items():
            savings_pct = stats.get('savings_percentage', 0)
            if savings_pct > 0:
                print(f'  âœ… {batch_type}: {savings_pct:.1f}% cost savings')
            elif savings_pct == 0:
                print(f'  ğŸŸ¡ {batch_type}: Cost neutral (no significant difference)')
            else:
                print(f'  âš ï¸  {batch_type}: {abs(savings_pct):.1f}% more expensive')
                print(f'      This may be due to complex batch prompts requiring more tokens')
    
    if analysis.get('recommendations'):
        print('\nğŸ’¡ Recommendations:')
        for rec in analysis['recommendations']:
            print(f'  â€¢ {rec}')
    
    # Show some sample results
    if results:
        print(f'\nğŸ¯ Sample Results:')
        for i, candidate in enumerate(results[:2], 1):
            print(f'  Idea {i}: {candidate["idea"][:60]}...')
            print(f'    Score: {candidate["initial_score"]} â†’ {candidate["improved_score"]} (Î”{candidate["score_delta"]})')
        
except Exception as e:
    print(f'âŒ Test failed: {e}')
    import traceback
    traceback.print_exc()

print('\nğŸ Comprehensive monitoring test complete!')