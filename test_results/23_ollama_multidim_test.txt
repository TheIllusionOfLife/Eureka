2025-11-18 23:06:37 - INFO - LLM provider flags (--provider ollama) configured. Router is enabled (Ollama-first default).
2025-11-18 23:06:37 - INFO - Using default constraints
2025-11-18 23:06:37 - INFO - Temperature Settings:
  Base: 0.7
  Idea Generation: 0.9
  Evaluation: 0.3
  Advocacy: 0.5
  Skepticism: 0.5
2025-11-18 23:06:37 - INFO - Running MadSpark workflow with theme: 'test ollama integration'
2025-11-18 23:06:37 - INFO - Constraints: Generate practical and innovative ideas
2025-11-18 23:06:37 - INFO - Using synchronous execution
2025-11-18 23:06:37 - INFO - Enhanced reasoning engine initialized
2025-11-18 23:06:37 - INFO - Router initialized: primary=ollama, tier=fast, fallback=True, cache=True
2025-11-18 23:06:37 - INFO - Initialized cache at /Users/yuyamukai/.cache/madspark/llm (max size: 1000MB)
2025-11-18 23:06:37 - INFO - HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2025-11-18 23:06:37 - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models "HTTP/1.1 200 OK"
2025-11-18 23:06:37 - INFO - AFC is enabled with max remote calls: 10.
